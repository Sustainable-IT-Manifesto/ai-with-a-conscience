## **How to Conduct an Ethical Impact Assessment (EIA)**

An **Ethical Impact Assessment (EIA)** is a structured process to evaluate the potential ethical risks, benefits, and societal implications of deploying an AI system. This guide outlines a step-by-step approach for conducting an EIA and highlights how it links to Environmental, Social, and Governance (ESG) reporting.


---
## **Use Case for Conducting an Ethical Impact Assessment (EIA)**

#### **Scenario**: Developing an AI-Powered Hiring Platform
**Objective**: A startup is building an AI platform to streamline hiring by screening resumes, ranking candidates, and matching them with job requirements. The system uses Natural Language Processing (NLP) to analyze candidate profiles and match them with open positions.

---

#### **Why Conduct an EIA?**
1. **Fairness Concerns**: To ensure the AI does not exhibit bias against candidates based on gender, ethnicity, age, or other protected attributes.
2. **Transparency**: To ensure employers and candidates understand how the AI evaluates and ranks profiles.
3. **Privacy**: To protect sensitive candidate information collected during the hiring process.
4. **Accountability**: To clearly define responsibilities if the platform makes unethical or erroneous decisions.
5. **Sustainability**: To evaluate the system’s environmental impact, especially regarding energy usage in AI operations.

---

#### **EIA Process for the Use Case**

1. **Define the Scope**:
   - **Purpose**: The platform aims to reduce hiring timelines and increase the accuracy of job-candidate matches.
   - **Stakeholders**: Employers, candidates, recruiters, and the development team.
   - **Data Used**: Resumes, job descriptions, candidate assessments, and company requirements.
   - **Regulatory Considerations**: Compliance with employment laws, data privacy laws (GDPR, CCPA).

   **Deliverables**:
   - **System Overview Document**: Detailed description of the platform’s scope and capabilities.
   - **Stakeholder Map**: Employers (clients), job applicants (users), regulators.

---

2. **Identify Ethical Risks and Benefits**:
   - **Risks**:
     - **Bias**: AI may favor candidates with traditionally male-dominated career paths.
     - **Transparency**: Lack of clarity on how resumes are ranked.
     - **Privacy**: Sensitive data such as candidate demographics could be mishandled.
   - **Benefits**:
     - Faster hiring processes.
     - Objective screening process.
     - Improved access to job opportunities for underrepresented groups if designed well.

   **Deliverables**:
   - **Ethical Risk Register**: Identifies high-likelihood risks like dataset bias and transparency issues.
   - **Benefits Report**: Highlights time savings and potential for inclusivity improvements.

---

3. **Engage Stakeholders**:
   - Conduct interviews with HR teams to understand hiring pain points.
   - Gather feedback from candidates on their concerns with automated hiring.
   - Host workshops with diversity and inclusion experts to review algorithm design.

   **Deliverables**:
   - **Stakeholder Feedback Report**: Summarizes concerns like bias and lack of clarity.

---

4. **Assess Alignment with Ethical Principles**:
   - Compare the platform’s design with principles of fairness (bias mitigation), transparency (explainable AI), and privacy.
   - Use a checklist to ensure compliance.

   **Deliverables**:
   - **Ethical Compliance Checklist**: Identifies areas needing improvement, such as insufficient transparency in the ranking process.

---

5. **Develop Mitigation Strategies**:
   - Retrain the model using diverse datasets to address bias.
   - Implement explainability features to show employers why candidates are ranked a certain way.
   - Encrypt sensitive data to protect candidate privacy.

   **Deliverables**:
   - **Risk Mitigation Plan**: Includes retraining timelines and security upgrades.

---

6. **Test and Validate the AI System**:
   - Run pilot tests with anonymized resumes to check for bias in rankings.
   - Simulate edge cases, like resumes with identical qualifications but different demographic information.

   **Deliverables**:
   - **Testing Report**: Documents instances of bias and measures effectiveness of fixes.

---

7. **Monitor and Review Post-Deployment**:
   - Track KPIs like candidate satisfaction and diversity metrics.
   - Periodically audit the AI system to ensure continued fairness and transparency.

   **Deliverables**:
   - **Monitoring Dashboard**: Tracks metrics such as candidate diversity and system uptime.
   - **Post-Deployment Review Report**: Reviews findings from ongoing audits.

---

8. **Document and Report Findings**:
   - Share the results of the EIA with employers and regulators to demonstrate accountability.
   - Publish a summary for candidates to build trust.

   **Deliverables**:
   - **EIA Final Report**: Includes risks, mitigations, and audit results.
   - **Public Summary**: Explains the platform’s ethical considerations in simple terms.

---

This use case demonstrates the importance of conducting an EIA to ensure ethical AI deployment, build trust among stakeholders, and align with societal and regulatory expectations.


---

## Process 

### **1. Define the Scope of the AI System**
Start by clearly defining the purpose, scope, and functionality of the AI system under review.

#### Key Questions:
- What is the intended purpose of the AI system?
- Who are the primary stakeholders (e.g., users, employees, customers, communities)?
- What data will the system use, and how will it be collected, stored, and processed?
- Are there any specific legal or regulatory requirements related to this system?

#### ESG Linkage:
- **Governance**: Defining the scope ensures compliance with legal and regulatory frameworks, aligning with governance best practices.
- **Social**: Identifying stakeholders ensures inclusion and equitable outcomes, contributing to social responsibility goals.

#### Deliverables:
- **System Overview Document**: A concise description of the AI system’s goals, capabilities, and scope of use.
- **Stakeholder Map**: Identify all individuals or groups potentially impacted by the system.

**Worksheet Example:**
| **Question** | **Response** |
|--------------|--------------|
| System Purpose | (e.g., Automate customer service responses) |
| Stakeholders | (e.g., End users, customer support staff, management) |
| Data Sources | (e.g., CRM data, support tickets, user feedback) |
| Regulatory Requirements | (e.g., GDPR compliance, CCPA adherence) |

---

### **2. Identify Potential Ethical Risks and Benefits**
Conduct a risk-benefit analysis to assess how the AI system might positively or negatively impact stakeholders.

#### Areas to Evaluate:
- **Fairness and Bias**:
  - Could the system produce biased or discriminatory outcomes?
  - Are the datasets representative of diverse populations?

- **Transparency**:
  - Can users understand how decisions are made by the AI?
  - Are explanations for decisions accessible to non-technical stakeholders?

- **Privacy**:
  - Is personal data collected and processed ethically and securely?
  - Are users informed and able to consent to data usage?

- **Accountability**:
  - Who is responsible if the AI system causes harm?
  - Is there a process to address grievances or disputes?

- **Environmental Impact**:
  - Does the system’s operation align with sustainability goals?
  - What is the energy consumption of the AI infrastructure?

#### ESG Linkage:
- **Environmental**: Addressing energy consumption and sustainability aligns with environmental reporting.
- **Social**: Ensuring fairness, privacy, and inclusivity supports social equity.
- **Governance**: Accountability mechanisms demonstrate ethical leadership and risk management.

#### Deliverables:
- **Ethical Risk Register**: A document listing potential risks, their severity, and mitigation strategies.
- **Benefits Report**: A summary of expected positive outcomes.

**Worksheet Example:**
| **Risk** | **Likelihood** | **Impact** | **Mitigation** |
|----------|----------------|------------|----------------|
| Dataset Bias | High | High | Increase diversity in datasets |
| Energy Consumption | Medium | High | Optimize computational processes |

---

### **3. Engage Stakeholders**
Gather input from diverse stakeholders to ensure their perspectives are considered.

#### Steps:
1. **Stakeholder Interviews**: Speak with users, employees, community representatives, and domain experts to identify concerns and expectations.
2. **Workshops**: Host collaborative sessions to discuss ethical considerations and solicit feedback.
3. **Surveys**: Use structured questionnaires to collect input on the AI system’s design and impact.

#### ESG Linkage:
- **Social**: Engaging stakeholders promotes inclusivity and ensures the system addresses societal needs.
- **Governance**: Transparent stakeholder engagement strengthens trust and accountability.

#### Deliverables:
- **Stakeholder Feedback Report**: A synthesis of insights and recommendations gathered during engagement activities.

**Worksheet Example:**
| **Stakeholder Group** | **Feedback** | **Proposed Actions** |
|------------------------|--------------|----------------------|
| Employees | Concerns about job automation | Focus on augmentation, not replacement |
| Customers | Data privacy concerns | Enhance encryption and consent processes |

---

### **4. Assess Alignment with Ethical Principles**
Evaluate the AI system against established ethical principles, such as fairness, accountability, privacy, and sustainability.

#### Steps:
- Compare the system’s design and functionality to your organization’s Ethical AI Policy.
- Use a checklist or framework (e.g., FAIR principles, IEEE’s Ethically Aligned Design) to assess compliance.
- Identify areas where the system’s implementation deviates from ethical guidelines.

#### ESG Linkage:
- **Governance**: Ensuring alignment with ethical principles supports transparent and responsible governance practices.
- **Social**: Focusing on fairness and accountability enhances societal trust in technology.

#### Deliverables:
- **Ethical Compliance Checklist**: A document highlighting areas of alignment and gaps.

**Worksheet Example:**
| **Principle** | **Compliance** | **Gaps Identified** | **Actions Required** |
|---------------|----------------|---------------------|----------------------|
| Fairness | Yes | None | N/A |
| Privacy | No | Consent mechanism inadequate | Revise consent process |

---

### **5. Develop Mitigation Strategies**
For each identified risk, create actionable strategies to minimize harm and improve outcomes.

#### Steps:
1. **Prioritize Risks**: Use a risk matrix to categorize risks by likelihood and impact.
2. **Define Mitigation Actions**: Specify measures to address each risk (e.g., improving dataset diversity, adding explainability features, or strengthening data security).
3. **Assign Responsibility**: Clearly identify who will implement and monitor each mitigation strategy.

#### ESG Linkage:
- **Governance**: Demonstrating proactive risk management aligns with governance expectations in ESG reporting.
- **Environmental**: Mitigating high energy consumption contributes to sustainability goals.
- **Social**: Addressing bias and privacy concerns fosters ethical innovation.

#### Deliverables:
- **Risk Mitigation Plan**: A prioritized list of actions with assigned responsibilities and timelines.

**Worksheet Example:**
| **Risk** | **Mitigation Action** | **Owner** | **Deadline** |
|----------|------------------------|-----------|--------------|
| Lack of Transparency | Develop explainability tools | AI Team | Q3 2025 |
| Energy Use | Transition to green servers | IT Team | Q2 2025 |

---

### **6. Test and Validate the AI System**
Conduct testing to validate the system’s behavior under real-world conditions and ensure ethical safeguards are effective.

#### Steps:
- **Pilot Testing**: Deploy the system in a controlled environment to observe its impact.
- **Simulations**: Test edge cases and scenarios to identify unintended consequences.
- **Audits**: Perform third-party or internal audits to validate compliance with ethical standards.

#### ESG Linkage:
- **Governance**: Regular testing and audits demonstrate commitment to accountability and risk management.
- **Social**: Validation ensures that the system meets societal expectations and does not harm vulnerable groups.

#### Deliverables:
- **Testing Report**: Findings from pilot tests and simulations.
- **Audit Report**: Results from compliance audits.

**Worksheet Example:**
| **Test Scenario** | **Expected Outcome** | **Actual Outcome** | **Action Needed** |
|-------------------|----------------------|--------------------|-------------------|
| High user traffic | No delays | Minor delays observed | Optimize algorithms |

---

### **7. Monitor and Review Post-Deployment**
Ethical impact assessment is an ongoing process. Regularly monitor the AI system’s performance and update the assessment as needed.

#### Steps:
1. **Establish Monitoring Metrics**: Define key performance indicators (KPIs) related to fairness, transparency, privacy, and sustainability.
2. **Collect Feedback**: Continuously gather feedback from users and other stakeholders.
3. **Periodic Reviews**: Schedule regular reviews to reassess ethical risks and benefits.

#### ESG Linkage:
- **Environmental**: Monitoring energy usage supports environmental metrics in ESG reports.
- **Social**: Tracking fairness and inclusivity metrics aligns with social responsibility goals.
- **Governance**: Continuous monitoring demonstrates accountability and ethical oversight.

#### Deliverables:
- **Monitoring Dashboard**: A real-time overview of ethical KPIs.
- **Post-Deployment Review Report**: Periodic updates on the system’s ethical performance.

**Worksheet Example:**
| **Metric** | **Target** | **Current** | **Action Needed** |
|------------|------------|-------------|-------------------|
| Recommendation Bias | <5% | 8% | Retrain model |
| Energy Efficiency | 90% | 85% | Upgrade servers |

---

### **8. Document and Report Findings**
Maintain detailed documentation of the EIA process to demonstrate accountability and compliance.

#### Steps:
- Summarize findings from each phase of the EIA.
- Share reports with stakeholders, regulators, or certification bodies as needed.
- Publish key insights (where appropriate) to foster transparency and build trust.

#### ESG Linkage:
- **Governance**: Detailed reporting aligns with ESG requirements for transparency and accountability.
- **Social**: Public summaries of ethical considerations build societal trust and demonstrate social responsibility.

#### Deliverables:
- **EIA Final Report**: A comprehensive document summarizing the entire assessment process.
- **Public Summary**: A user-friendly version of the report for external stakeholders.

**Worksheet Example:**
| **Report Section** | **Details** |
|--------------------|-------------|
| Executive Summary | Key findings and recommendations |
| Risk Analysis | High-priority risks and mitigations |

---

### **9. Continuously Improve the EIA Process**
Learn from each EIA to refine and improve future assessments.

#### Steps:
- Solicit feedback from the team and stakeholders involved in the EIA process.
- Analyze what worked well and where improvements are needed.
- Update internal guidelines and templates based on lessons learned.

#### ESG Linkage:
- **Governance**: Iterative improvements reflect commitment to high standards of accountability.
- **Environmental and Social**: Continuous optimization ensures the system’s alignment with ESG goals.

#### Deliverables:
- **EIA Improvement Plan**: Recommendations for enhancing future assessments.

**Worksheet Example:**
| **Area for Improvement** | **Proposed Change** | **Owner** | **Deadline** |
|--------------------------|---------------------|-----------|--------------|
| Stakeholder Feedback Loops | Automate surveys post-deployment | Operations | Q4 2025 |

---

### **EIA Checklist Summary**
- [ ] Define the scope of the AI system.
- [ ] Identify ethical risks and benefits.
- [ ] Engage stakeholders for input.
- [ ] Assess alignment with ethical principles.
- [ ] Develop and prioritize mitigation strategies.
- [ ] Test and validate the system.
- [ ] Monitor and review post-deployment.
- [ ] Document and report findings.
- [ ] Continuously improve the EIA process.


---


![](../imgs/SITM-logo-100x100.svg) This document was prepared by the Sustainable IT Manifesto Foundation, http://sustainableITmanifesto.


**Tech has a big carbon footprint. We want to change that**
